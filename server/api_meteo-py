from fastapi import FastAPI, Request, Query
from fastapi.responses import PlainTextResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import asyncio
import json
import math
import os
import time
from datetime import datetime, timezone
from zoneinfo import ZoneInfo
from decimal import Decimal

import mysql.connector
from mysql.connector import pooling

try:
    import httpx  # opcional
except Exception:
    httpx = None

app = FastAPI()

# CORS – restringe ao teu site
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://brisamar.franquinho.info"],
    allow_credentials=False,
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["*"],
)

# -------------------- Config --------------------
DB_CONFIG = {
    "host": "localhost",
    "user": "meteo_user",
    "password": "cmrf.m3t30",
    "database": "meteo"
}

DB_POOL = pooling.MySQLConnectionPool(pool_name="meteo_pool", pool_size=5, **DB_CONFIG)

LOG_DIR = "/home/carlos/meteo_logs"
os.makedirs(LOG_DIR, exist_ok=True)

PAYLOAD_LOG = os.path.join(LOG_DIR, "payloads.log")

LIVE_FILE = "/var/lib/meteo/live.json"   # <- ou /home/carlos/meteo-runtime/live.json
os.makedirs(os.path.dirname(LIVE_FILE), exist_ok=True)

DATA_STALE_SEC = 360                  # > 6 minutos = stale


METAR_TTL_S = 15 * 60
CACHE_DIR   = "/var/lib/meteo"
os.makedirs(CACHE_DIR, exist_ok=True)

def cache_path(icao: str) -> str:
    return os.path.join(CACHE_DIR, f"metar_{icao.upper()}.json")

# -------------------- Helpers --------------------
def f_to_c(f): return round((f - 32) * 5.0 / 9.0, 1)
def mph_to_kmh(mph): return round(mph * 1.60934, 1)
def in_to_mm(inches): return round(inches * 25.4, 2)
def inHg_to_hPa(inhg): return round(inhg * 33.8639, 1)

def save_live_json(data: dict):
    tmp_path = LIVE_FILE + ".tmp"
    with open(tmp_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2, default=_json_default)
    os.replace(tmp_path, LIVE_FILE)

def to_float(d: dict, key: str):
    try:
        v = d.get(key)
        if v is None:
            return None
        s = str(v).strip()
        if s in ("", "NA", "nan", "NaN"):
            return None
        return float(s)
    except Exception:
        return None

def dewpoint_from_temp_rh(t_c: float, rh_pct: float):
    # Magnus-Tetens (válida ~0–60 °C)
    if t_c is None or rh_pct is None or rh_pct <= 0:
        return None
    a, b = 17.62, 243.12
    gamma = (a * t_c) / (b + t_c) + math.log(rh_pct / 100.0)
    return round((b * gamma) / (a - gamma), 1)

def rh_from_temp_vpd(t_c: float, vpd_kpa: float):
    # Se a humidade faltar mas houver VPD, estima RH
    if t_c is None or vpd_kpa is None:
        return None
    es = 0.6108 * math.exp(17.27 * t_c / (t_c + 237.3))  # kPa
    avp = es - vpd_kpa
    if avp <= 0:
        return 0.0
    rh = (avp / es) * 100.0
    return max(0.0, min(100.0, rh))

def _json_default(o):
    if isinstance(o, Decimal):
        return float(o)
    if isinstance(o, datetime):
        return o.isoformat()
    return str(o)

def apparent_temperature_c(t_c: float | None, rh_pct: float | None, wind_kmh: float | None) -> float | None:
    """
    "Feels like" em °C.
    - Wind Chill (Canadá) quando T <= 10°C e vento >= 4.8 km/h
    - Caso contrário, Apparent Temperature (BoM/Austrália)
    """
    if t_c is None or rh_pct is None:
        return None
    try:
        v_kmh = float(wind_kmh or 0.0)
    except Exception:
        v_kmh = 0.0

    if t_c <= 10.0 and v_kmh >= 4.8:
        wc = 13.12 + 0.6215 * t_c - 11.37 * (v_kmh ** 0.16) + 0.3965 * t_c * (v_kmh ** 0.16)
        return round(wc, 1)

    wind_ms = v_kmh / 3.6
    e = (rh_pct / 100.0) * 6.105 * math.exp(17.27 * t_c / (237.7 + t_c))
    at = t_c + 0.33 * e - 0.70 * wind_ms - 4.00
    return round(at, 1)


# -------------------- Endpoints --------------------

@app.get("/metar-tgftp/{icao}")
async def metar_tgftp(icao: str):
    icao = icao.upper().strip()
    cpath = cache_path(icao)

    # 1) tenta devolver cache fresca
    if os.path.exists(cpath) and (time.time() - os.path.getmtime(cpath) < METAR_TTL_S):
        with open(cpath, "r", encoding="utf-8") as f:
            cached = json.load(f)
        return JSONResponse(content=cached, headers={"Cache-Control": "no-store"})

    # 2) tenta buscar à NOAA (com httpx se houver; caso contrário urllib)
    url = f"https://tgftp.nws.noaa.gov/data/observations/metar/stations/{icao}.TXT"
    lines = None
    try:
        if httpx is not None:
            async with httpx.AsyncClient(timeout=10) as cli:
                r = await cli.get(url)
                r.raise_for_status()
                txt = r.text
        else:
            # fallback stdlib (bloqueante, mas raramente chamado por causa do cache)
            import urllib.request
            with urllib.request.urlopen(url, timeout=10) as resp:
                txt = resp.read().decode("utf-8", errors="replace")

        lines = [ln.strip() for ln in txt.strip().splitlines() if ln.strip()]
    except Exception as e:
        # 3) se falhar, devolve cache antiga se existir
        if os.path.exists(cpath):
            with open(cpath, "r", encoding="utf-8") as f:
                cached = json.load(f)
            return JSONResponse(content=cached, headers={"Cache-Control": "no-store"})
        # sem cache: devolve erro útil
        return JSONResponse(
            status_code=502,
            content={"ok": False, "error": "fetch_failed", "detail": str(e)}
        )

    # 4) construir objeto de saída
    obs_time = lines[0].replace("/", "-") if lines else ""
    raw = " ".join(lines[1:]) if lines and len(lines) > 1 else ""
    out = {"ok": True, "time": obs_time, "raw": raw}

    # 5) guardar cache como JSON “limpo”
    tmp = cpath + ".tmp"
    with open(tmp, "w", encoding="utf-8") as f:
        json.dump(out, f, ensure_ascii=False, indent=2)
    os.replace(tmp, cpath)

    return JSONResponse(content=out, headers={"Cache-Control": "no-store"})


@app.get("/health")
def health():
    return PlainTextResponse("OK")


@app.api_route("/api", methods=["GET", "POST"])
@app.api_route("/api/", methods=["GET", "POST"], include_in_schema=False)
async def ecowitt_report(request: Request):
    # 1) obter dados (POST form ou query string)
    data = {}
    try:
        form = await request.form()
        data = dict(form)
    except Exception:
        pass
    if not data:
        data = dict(request.query_params)

    # 2) log bruto (apenas para debugging)
    try:
        with open(PAYLOAD_LOG, "a", encoding="utf-8") as f:
            f.write(f"{datetime.utcnow().isoformat()}Z {json.dumps(data)}\n")
    except Exception:
        pass

    # 3) conversões
    tempf = to_float(data, "tempf")
    temp_c = f_to_c(tempf) if tempf is not None else None

    rh_pct = to_float(data, "humidity")
    if rh_pct is None:
        rh_pct = rh_from_temp_vpd(temp_c, to_float(data, "vpd"))

    dewptf = to_float(data, "dewptf")
    if dewptf is not None:
        dewpoint_c = f_to_c(dewptf)
    else:
        dewpoint_c = dewpoint_from_temp_rh(temp_c, rh_pct)

    wind_kmh     = mph_to_kmh(to_float(data, "windspeedmph") or 0.0)
    gust_kmh     = mph_to_kmh(to_float(data, "windgustmph") or 0.0)
    wind_dir_deg = to_float(data, "winddir")

    pressure_hpa = inHg_to_hPa(
        (to_float(data, "baromrelin") if to_float(data, "baromrelin") is not None else None)
        or (to_float(data, "baromabsin") if to_float(data, "baromabsin") is not None else None)
        or 0.0
    )

    rain_rate_mmph = in_to_mm(to_float(data, "rainratein") or 0.0)
    rain_day_mm    = in_to_mm(to_float(data, "dailyrainin") or 0.0)
    solar_wm2      = to_float(data, "solarradiation")
    uv_index       = to_float(data, "uv")

    # timestamps (com fuso local)
    tz       = ZoneInfo("Europe/Lisbon")
    ts_utc   = datetime.now(timezone.utc)
    ts_local = ts_utc.astimezone(tz)

    # 4) apparent temperature
    apparent_c = apparent_temperature_c(temp_c, rh_pct, wind_kmh)

    # 5) BD: calcular extremos do dia + inserir esta leitura
    def _insert_and_extremes():
        conn = DB_POOL.get_connection()
        cur = conn.cursor()
        try:
            # extremos já existentes para o dia local
            cur.execute("""
                SELECT MIN(temp_c), MAX(temp_c)
                FROM observations
                WHERE station_id = %s
                  AND DATE(ts_local) = DATE(%s)
            """, ("meteomg", ts_local))
            row = cur.fetchone() or (None, None)
            prev_min, prev_max = row

            # normalizar possíveis Decimals para float
            prev_min = float(prev_min) if prev_min is not None else None
            prev_max = float(prev_max) if prev_max is not None else None

            # incluir a leitura atual
            tmin = prev_min
            tmax = prev_max
            if temp_c is not None:
                tmin = temp_c if (prev_min is None or temp_c < prev_min) else prev_min
                tmax = temp_c if (prev_max is None or temp_c > prev_max) else prev_max

            # INSERT com min/max/apparent
            cur.execute("""
                INSERT INTO observations
                (station_id, ts_local, ts_utc,
                 temp_c, temp_max_c, temp_min_c,
                 rh_pct, dewpoint_c,
                 wind_kmh, gust_kmh, wind_dir_deg,
                 pressure_hpa, rain_rate_mmph, rain_day_mm,
                 solar_wm2, apparent_c, uv_index)
                VALUES
                (%s, %s, %s,
                 %s, %s, %s,
                 %s, %s,
                 %s, %s, %s,
                 %s, %s, %s,
                 %s, %s, %s)
            """, (
                "meteomg", ts_local, ts_utc,
                temp_c, tmax, tmin,
                rh_pct, dewpoint_c,
                wind_kmh, gust_kmh, wind_dir_deg,
                pressure_hpa, rain_rate_mmph, rain_day_mm,
                solar_wm2, apparent_c, uv_index
            ))
            conn.commit()
            return tmin, tmax
        finally:
            try:
                cur.close()
            finally:
                conn.close()

    try:
        tmin, tmax = await asyncio.to_thread(_insert_and_extremes)
    except Exception as e:
        # se a BD falhar, loga e prossegue (não impede o live.json)
        tmin, tmax = None, None
        try:
            with open(os.path.join(LOG_DIR, "db_errors.log"), "a", encoding="utf-8") as f:
                f.write(f"{datetime.utcnow().isoformat()}Z DB_FAIL {e}\n")
        except Exception:
            pass

    # 6) live.json (já com min/max e apparent)
    live_payload = {
        "v": 1,
        "station": "meteomg",
        "ts_utc": ts_utc.isoformat().replace("+00:00", "Z"),
        "ts_local": ts_local.isoformat(),
        "age_s": 0,
        "stale": False,
        "temp_c": temp_c,
        "temp_max_c": tmax,
        "temp_min_c": tmin,
        "apparent_c": apparent_c,
        "rh_pct": rh_pct,
        "dewpoint_c": dewpoint_c,
        "wind_kmh": wind_kmh,
        "gust_kmh": gust_kmh,
        "wind_dir_deg": wind_dir_deg,
        "pressure_hpa": pressure_hpa,
        "rain_rate_mmph": rain_rate_mmph,
        "rain_day_mm": rain_day_mm,
        "solar_wm2": solar_wm2,
        "uv_index": uv_index,
    }

    try:
        save_live_json(live_payload)
    except Exception as e:
        with open(os.path.join(LOG_DIR, "live_errors.log"), "a", encoding="utf-8") as f:
            f.write(f"{datetime.utcnow().isoformat()}Z LIVE_FAIL {e}\n")

    return PlainTextResponse("Success. Update done\n")


@app.get("/latest")
async def latest_observation():
    conn = mysql.connector.connect(**DB_CONFIG)
    cur = conn.cursor(dictionary=True)
    cur.execute("""
        SELECT * FROM observations
        ORDER BY ts_local DESC
        LIMIT 1
    """)
    row = cur.fetchone()
    cur.close()
    conn.close()
    if row:
        return JSONResponse(content=row, headers={"Cache-Control": "no-store"})
    else:
        return JSONResponse(content={"error": "No data found"}, status_code=404)


@app.get("/live")
async def get_live():
    if not os.path.exists(LIVE_FILE):
        return JSONResponse(
            status_code=503,
            content={"v": 1, "error": "no_live_data", "message": "Live JSON not ready"}
        )

    with open(LIVE_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)

    ts_utc = datetime.fromisoformat(data["ts_utc"].replace("Z", "+00:00"))
    age_s = (datetime.now(timezone.utc) - ts_utc).total_seconds()
    data["age_s"] = round(age_s, 1)
    data["stale"] = age_s > DATA_STALE_SEC

    return JSONResponse(content=data, headers={"Cache-Control": "no-store"})

@app.get("/history")
def history(hours: int = Query(24, ge=1, le=168)):
    conn = mysql.connector.connect(**DB_CONFIG)
    cur = conn.cursor(dictionary=True)
    cur.execute("""
        SELECT ts_local, ts_utc, temp_c, rain_day_mm, rain_rate_mmph
        FROM observations
        WHERE ts_utc >= (UTC_TIMESTAMP() - INTERVAL %s HOUR)
        ORDER BY ts_local ASC
    """, (hours,))
    rows = cur.fetchall()
    cur.close()
    conn.close()
    return rows
